{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWOh6WMdUq3b",
        "outputId": "000ea2f0-7cb6-488b-d30f-6f14e36ee5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/138.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install groq python-dotenv --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter GROQ API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6KhPBlHUzkr",
        "outputId": "83418b57-01b2-400e-f1bb-721e0b8986bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter GROQ API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "# UPDATED MODEL\n",
        "BASE_MODEL = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": \"\"\"You are a Technical Support Expert.\n",
        "Provide precise debugging and code fixes.\"\"\"\n",
        "    },\n",
        "\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": \"\"\"You are a Billing Support Expert.\n",
        "Be empathetic and explain billing policies.\"\"\"\n",
        "    },\n",
        "\n",
        "    \"general\": {\n",
        "        \"system_prompt\": \"\"\"You are a friendly general assistant.\"\"\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Router\n",
        "def route_prompt(user_input):\n",
        "\n",
        "    router_prompt = f\"\"\"\n",
        "Classify into ONE category:\n",
        "\n",
        "technical\n",
        "billing\n",
        "general\n",
        "\n",
        "Return ONLY the category.\n",
        "\n",
        "Query: {user_input}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a classifier.\"},\n",
        "            {\"role\": \"user\", \"content\": router_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    category = response.choices[0].message.content.strip().lower()\n",
        "\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    return category\n",
        "\n",
        "\n",
        "# Orchestrator\n",
        "def process_request(user_input):\n",
        "\n",
        "    category = route_prompt(user_input)\n",
        "\n",
        "    print(\"[Router]:\", category)\n",
        "\n",
        "    system_prompt = MODEL_CONFIG[category][\"system_prompt\"]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0.7,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# Test\n",
        "print(process_request(\"My python script throws IndexError at line 10.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzAHCYesVLX0",
        "outputId": "f37f484d-d02b-4fba-d6d4-91e4bbeb65d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router]: technical\n",
            "To help you debug the issue, I'll need more information. Can you please provide the following:\n",
            "\n",
            "1. The Python script that's throwing the error\n",
            "2. The exact error message, including the line number (which you've mentioned as 10)\n",
            "3. Any relevant context or data that might be causing the issue\n",
            "\n",
            "Without seeing the code, it's difficult to provide a precise solution. However, I can give you some general guidance on how to troubleshoot an `IndexError` in Python:\n",
            "\n",
            "* An `IndexError` typically occurs when you try to access an element in a list or other sequence using an index that is out of range.\n",
            "* Check the line of code that's throwing the error (line 10) and verify that the index you're using is valid.\n",
            "* Make sure that the list or sequence you're working with is not empty, and that the index you're using is within the bounds of the sequence.\n",
            "\n",
            "If you provide the code and more context, I can help you identify the issue and provide a specific fix.\n",
            "\n",
            "Example of how to report the issue:\n",
            "```python\n",
            "# your code here\n",
            "```\n",
            "Error message:\n",
            "```\n",
            "IndexError: list index out of range\n",
            "```\n",
            "Please paste your code, and I'll do my best to help you debug the issue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(process_request(\"I was charged twice for my subscription\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o77yGKpXVkw7",
        "outputId": "31753668-174c-48ac-f1c3-f78adbf3e48d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router]: billing\n",
            "I'm so sorry to hear that you were charged twice for your subscription. I can imagine how frustrating that must be for you. \n",
            "\n",
            "First, please know that I'm here to help resolve this issue as quickly as possible. I'll do my best to explain what might have happened and guide you through the process of getting a refund for the duplicate charge.\n",
            "\n",
            "It's possible that the duplicate charge was an error on our part, and I apologize for any inconvenience this has caused. To investigate further, could you please provide me with more details about the charges? This includes:\n",
            "\n",
            "1. The date of the duplicate charge\n",
            "2. The amount of the charge\n",
            "3. Your subscription ID or account number (if you have it handy)\n",
            "\n",
            "Once I have this information, I can look into the matter and work with our billing team to rectify the situation. If the duplicate charge was indeed an error, I'll make sure to process a refund for the incorrect amount as soon as possible.\n",
            "\n",
            "Additionally, I want to assure you that we take situations like this very seriously and are committed to preventing them from happening in the future. Your satisfaction and trust are our top priority, and I appreciate your patience and cooperation in resolving this matter.\n",
            "\n",
            "Please let me know if you have any questions or concerns, and I'll do my best to address them. I'm here to help and want to ensure that you're completely satisfied with the outcome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(process_request(\"Hello, how are you?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw2pS6N2VmTY",
        "outputId": "f14f104e-b88f-480d-b20d-8af8b4504db5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router]: general\n",
            "Hello. I'm doing well, thanks for asking. It's nice to meet you. Is there something I can help you with or would you like to chat? I'm here to assist you with any questions or topics you'd like to discuss.\n"
          ]
        }
      ]
    }
  ]
}